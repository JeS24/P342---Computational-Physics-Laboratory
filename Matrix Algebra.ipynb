{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matrix Algebra\n",
    "\n",
    "* Jacobi Iteration\n",
    "* Gauss-Seidel Method\n",
    "* Back Substitution\n",
    "* Forward Substitution\n",
    "* Gauss-Jordan Elimination\n",
    "* LU Decomposition (Without Explicit Pivoting)\n",
    "* Matrix Inversion\n",
    "* Cholesky Decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Imports\n",
    "import numpy as np, scipy as sc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix Equation: AX = B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Jacobi Iteration\n",
    "\n",
    "#### Iterative Formula:\n",
    "\n",
    "For a $N$ by $N$ matrix, $A = D + R$, where $D$ contains diagonal elements of $A$, and $R$ contains all other elements of $A$, but with all diagonal elements, set to 0.\n",
    "\n",
    "$$\\mathbf {x} ^{(k+1)}=D^{-1}\\left(\\mathbf {B} -R\\mathbf {x} ^{(k)}\\right)$$\n",
    "\n",
    "$$\\boxed{x_{i}^{(k+1)}={\\frac {1}{a_{ii}}}\\left(b_{i}-\\sum^{N-1}_{j\\neq i}a_{ij}x_{j}^{(k)}\\right),\\quad i=0,1,\\ldots (N-1)}$$\n",
    "Therefore,\n",
    "\n",
    "$$x_0^{(k+1)} = {\\frac {1}{a_{00}}}\\left(b_{0} - a_{01}x_{1}^{(k)} - a_{02}x_{2}^{(k)} - a_{03}x_{3}^{(k)}\\ldots\\right)$$\n",
    "\n",
    "$$x_1^{(k+1)} = {\\frac {1}{a_{11}}}\\left(b_{1} - a_{10}x_{0}^{(k)} - a_{12}x_{2}^{(k)} - a_{13}x_{3}^{(k)}\\ldots\\right)$$\n",
    "\n",
    "$$x_2^{(k+1)} = {\\frac {1}{a_{22}}}\\left(b_{2} - a_{20}x_{0}^{(k)} - a_{21}x_{1}^{(k)} - a_{23}x_{3}^{(k)}\\ldots\\right)$$\n",
    "\n",
    "$$x_3^{(k+1)} = {\\frac {1}{a_{33}}}\\left(b_{3} - a_{30}x_{0}^{(k)} - a_{31}x_{1}^{(k)} - a_{32}x_{2}^{(k)}\\ldots\\right)$$\n",
    "And so on...\n",
    "\n",
    "#### Merits:\n",
    "\n",
    "\n",
    "#### Demerits:\n",
    "\n",
    "* Does not guarantee convergence\n",
    "\n",
    "#### Notes: (From Wikipedia: https://en.wikipedia.org/wiki/Jacobi_method)\n",
    "\n",
    "* The standard convergence condition (for any iterative method) is when the spectral radius of the iteration matrix is less than 1: $\\rho (D^{-1}R)<1$.\n",
    "* A sufficient (but not necessary) condition for the method to converge is that the matrix A is strictly or irreducibly diagonally dominant. Strict row diagonal dominance means that for each row, the absolute value of the diagonal term is greater than the sum of absolute values of other terms: $\\left|a_{ii}\\right|>\\sum _{j\\neq i}{\\left|a_{ij}\\right|}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System of Linear Equations:\n",
      "\n",
      "4.0x0 + -1.0x1 + 1.0x2 = 7.0\n",
      "4.0x0 + -8.0x1 + 1.0x2 = 21.0\n",
      "-2.0x0 + 1.0x1 + 5.0x2 = 15.0\n",
      "\n",
      "Iteration Limit:  120 \n",
      "\n",
      "Iteration: 0 | Current Solution: [0.0, 0.0, 0.0]\n",
      "Iteration: 1 | Current Solution: [ 1.75  -2.625  3.   ]\n",
      "Iteration: 2 | Current Solution: [ 0.34375 -1.375    4.225  ]\n",
      "Iteration: 3 | Current Solution: [ 0.35   -1.925   3.4125]\n",
      "Iteration: 4 | Current Solution: [ 0.415625  -2.0234375  3.525    ]\n",
      "Iteration: 5 | Current Solution: [ 0.36289062 -1.9765625   3.5709375 ]\n",
      "Iteration: 6 | Current Solution: [ 0.363125   -1.9971875   3.54046875]\n",
      "Iteration: 7 | Current Solution: [ 0.36558594 -2.00087891  3.5446875 ]\n",
      "Iteration: 8 | Current Solution: [ 0.3636084  -1.99912109  3.54641016]\n",
      "Iteration: 9 | Current Solution: [ 0.36361719 -1.99989453  3.54526758]\n",
      "Iteration: 10 | Current Solution: [ 0.36370947 -2.00003296  3.54542578]\n",
      "Iteration: 11 | Current Solution: [ 0.36363531 -1.99996704  3.54549038]\n",
      "Iteration: 12 | Current Solution: [ 0.36363564 -1.99999604  3.54544753]\n",
      "Iteration: 13 | Current Solution: [ 0.36363911 -2.00000124  3.54545347]\n",
      "Iteration: 14 | Current Solution: [ 0.36363632 -1.99999876  3.54545589]\n",
      "Iteration: 15 | Current Solution: [ 0.36363634 -1.99999985  3.54545428]\n",
      "Iteration: 16 | Current Solution: [ 0.36363647 -2.00000005  3.54545451]\n",
      "Iteration: 17 | Current Solution: [ 0.36363636 -1.99999995  3.5454546 ]\n",
      "Iteration: 18 | Current Solution: [ 0.36363636 -1.99999999  3.54545454]\n",
      "Iteration: 19 | Current Solution: [ 0.36363637 -2.          3.54545454]\n",
      "Iteration: 20 | Current Solution: [ 0.36363636 -2.          3.54545455]\n",
      "Iteration: 21 | Current Solution: [ 0.36363636 -2.          3.54545455]\n",
      "Iteration: 22 | Current Solution: [ 0.36363636 -2.          3.54545455]\n",
      "Iteration: 23 | Current Solution: [ 0.36363636 -2.          3.54545455]\n",
      "\n",
      "Solution converged, after 23 iterations.\n",
      "\n",
      "SOLUTION:  [ 0.36363636 -2.          3.54545455]\n",
      "ERROR:  [-2.60591548e-12 -4.58847182e-10  4.23654001e-10]\n"
     ]
    }
   ],
   "source": [
    "def jacobi_iter(A, B, init_val, iter_lim, tol):\n",
    "    \"\"\"\n",
    "    # A: N by N np.array() | Contains coefficients of the variables (Matrix, A)\n",
    "    # B: N by 1 np.array() | Contains the constants on RHS (Vector, B)\n",
    "    # init_val: np.array() | Contains Initial Values\n",
    "    # iter_lim: Stores Iteration Limit\n",
    "    # tol: Tolerance value - how precise does the solution need to be\n",
    "    \"\"\"\n",
    "    CONV_FLAG = False # Convergence Flag\n",
    "    ITER_LIM = iter_lim\n",
    "    var = init_val # Vector, X\n",
    "    \n",
    "    print(\"System of Linear Equations:\\n\")\n",
    "    for i in range(A.shape[0]):\n",
    "        row = [\"{}x{}\".format(A[i, j], j) for j in range(A.shape[1])]\n",
    "        print(\" + \".join(row), \"=\", B[i])\n",
    "\n",
    "    print(\"\\nIteration Limit: \", ITER_LIM, \"\\n\")\n",
    "    \n",
    "    for i in range(ITER_LIM):\n",
    "        print(\"Iteration: {} | Current Solution: {}\".format(i, var))\n",
    "        var_new = np.zeros_like(var) # stores updated values of all variables (Vector, X)\n",
    "\n",
    "        for j in range(A.shape[0]):\n",
    "            # Matrix Multiplying all elements, before A's diagonal (in a row) with all corresponding vars (in Vector, X)\n",
    "            d = np.dot(A[j, :j], var[:j])\n",
    "            # Matrix Multiplying all elements, after A's diagonal (in a row) with all corresponding vars (in Vector, X)\n",
    "            r = np.dot(A[j, j + 1:], var[j + 1:])\n",
    "            # Updating values of vars\n",
    "            var_new[j] = (B[j] - d - r)/A[j, j]\n",
    "        \n",
    "        # Checks, how close the updated values are, to the previous iteration's values and breaks the loop, if close enough (defined by \"tol\")\n",
    "        if np.allclose(var, var_new, atol=tol, rtol=0.):\n",
    "            print(\"\\nSolution converged, after {} iterations.\".format(i))\n",
    "            CONV_FLAG = True\n",
    "            break\n",
    "\n",
    "        var = var_new # Storing the new solution\n",
    "    # If solution is not obtained (no convergence), after ITER_LIM iterations | Note that, this \"else\" block belongs to the previous \"for\" statement and not any \"if\" statement\n",
    "    else:\n",
    "        CONV_FLAG = False\n",
    "\n",
    "    # If Solution converged\n",
    "    if CONV_FLAG:\n",
    "        print(\"\\nSOLUTION: \", var)\n",
    "        print(\"ERROR: \", np.dot(A, var) - B) # Error in the obtained solution\n",
    "    else:\n",
    "        print(\"\\nSolution did not converge, after the specified limit of {} iterations.\".format(ITER_LIM))\n",
    "\n",
    "\n",
    "# Testing the procedure\n",
    "A = np.array([[4., -1., 1.],\n",
    "              [4., -8., 1.],\n",
    "              [-2., 1., 5.]])\n",
    "\n",
    "B = np.array([7., 21., 15.])\n",
    "\n",
    "jacobi_iter(A, B, init_val=[0.,0.,0.], iter_lim=120, tol=1e-10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Gauss-Seidel Method\n",
    "\n",
    "#### Iterative Formula:\n",
    "\n",
    "For a $N$ by $N$ matrix, $A = L_* + U$, where $L_*$ contains lower triangular elements of $A$, and $U$ (a strictly upper triangular matrix) contains all other elements of $A$.\n",
    "\n",
    "$$\\mathbf {x} ^{(k+1)}=L_{*}^{-1}(\\mathbf {b} -U\\mathbf {x} ^{(k)})$$\n",
    "\n",
    "$$\\boxed{{\\displaystyle x_{i}^{(k+1)}={\\frac {1}{a_{ii}}}\\left(b_{i}-\\sum _{j=0}^{i-1}a_{ij}x_{j}^{(k+1)}-\\sum _{j=i+1}^{N-1}a_{ij}x_{j}^{(k)}\\right),\\quad i=0,1\\dots ,(N-1).}}$$\n",
    "Therefore,\n",
    "\n",
    "$$x_0^{(k+1)} = {\\frac {1}{a_{00}}}\\left(b_{0} - a_{01}x_{1}^{(k)} - a_{02}x_{2}^{(k)} - a_{03}x_{3}^{(k)}\\ldots\\right)$$\n",
    "\n",
    "$$x_1^{(k+1)} = {\\frac {1}{a_{11}}}\\left(b_{1} - a_{10}x_{0}^{(k+1)} - a_{12}x_{2}^{(k)} - a_{13}x_{3}^{(k)}\\ldots\\right)$$\n",
    "\n",
    "$$x_2^{(k+1)} = {\\frac {1}{a_{22}}}\\left(b_{2} - a_{20}x_{0}^{(k+1)} - a_{21}x_{1}^{(k+1)} - a_{23}x_{3}^{(k)}\\ldots\\right)$$\n",
    "\n",
    "$$x_3^{(k+1)} = {\\frac {1}{a_{33}}}\\left(b_{3} - a_{30}x_{0}^{(k+1)} - a_{31}x_{1}^{(k+1)} - a_{32}x_{2}^{(k+1)}\\ldots\\right)$$\n",
    "And so on...\n",
    "\n",
    "#### Merits:\n",
    "\n",
    "* Faster than Jacobi Iteration\n",
    "* Same space complexity as Jacobi Iteration\n",
    "\n",
    "#### Demerits:\n",
    "\n",
    "* Does not guarantee convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System of Linear Equations:\n",
      "\n",
      "4.0x0 + -1.0x1 + 1.0x2 = 7.0\n",
      "4.0x0 + -8.0x1 + 1.0x2 = 21.0\n",
      "-2.0x0 + 1.0x1 + 5.0x2 = 15.0\n",
      "\n",
      "Iteration Limit:  120 \n",
      "\n",
      "Iteration: 1 | Current Solution: [0.0, 0.0, 0.0]\n",
      "Iteration: 2 | Current Solution: [ 1.75 -1.75  4.05]\n",
      "Iteration: 3 | Current Solution: [ 0.3     -1.96875  3.51375]\n",
      "Iteration: 4 | Current Solution: [ 0.379375   -1.99609375  3.55096875]\n",
      "Iteration: 5 | Current Solution: [ 0.36323437 -1.99951172  3.54519609]\n",
      "Iteration: 6 | Current Solution: [ 0.36382305 -1.99993896  3.54551701]\n",
      "Iteration: 7 | Current Solution: [ 0.36363601 -1.99999237  3.54545288]\n",
      "Iteration: 8 | Current Solution: [ 0.36363869 -1.99999905  3.54545528]\n",
      "Iteration: 9 | Current Solution: [ 0.36363642 -1.99999988  3.54545454]\n",
      "Iteration: 10 | Current Solution: [ 0.36363639 -1.99999999  3.54545455]\n",
      "Iteration: 11 | Current Solution: [ 0.36363637 -2.          3.54545455]\n",
      "Iteration: 12 | Current Solution: [ 0.36363636 -2.          3.54545455]\n",
      "Iteration: 13 | Current Solution: [ 0.36363636 -2.          3.54545455]\n",
      "\n",
      "Solution converged, after 12 iterations.\n",
      "\n",
      "SOLUTION:  [ 0.36363636 -2.          3.54545455]\n",
      "ERROR:  [ 8.94848640e-11 -1.14241061e-10  1.77635684e-15]\n"
     ]
    }
   ],
   "source": [
    "def gauss_seidel(A, B, init_val, iter_lim, tol):\n",
    "    \"\"\"\n",
    "    # A: N by N np.array() | Contains coefficients of the variables (Matrix, A)\n",
    "    # B: N by 1 np.array() | Contains the constants on RHS (Vector, B)\n",
    "    # init_val: np.array() | Contains Initial Values\n",
    "    # iter_lim: Stores Iteration Limit\n",
    "    # tol: Tolerance value - how precise does the solution need to be\n",
    "    \"\"\"\n",
    "    CONV_FLAG = False # Convergence Flag\n",
    "    ITER_LIM = iter_lim\n",
    "    var = init_val # Vector, X\n",
    "    \n",
    "    print(\"System of Linear Equations:\\n\")\n",
    "    for i in range(A.shape[0]):\n",
    "        row = [\"{}x{}\".format(A[i, j], j) for j in range(A.shape[1])]\n",
    "        print(\" + \".join(row), \"=\", B[i])\n",
    "\n",
    "    print(\"\\nIteration Limit: \", ITER_LIM, \"\\n\")\n",
    "    \n",
    "    for i in range(ITER_LIM):\n",
    "        print(\"Iteration: {} | Current Solution: {}\".format(i+1, var))\n",
    "        var_new = np.zeros_like(var) # stores updated values of all variables (Vector, X)\n",
    "\n",
    "        for j in range(A.shape[0]):\n",
    "            # Matrix Multiplying all elements, before A's diagonal (in a row) with all corresponding vars (in Vector, X), that now have updated values\n",
    "            l = np.dot(A[j, :j], var_new[:j]) # Note, the only change from jacobi_iter() is changing \"var\" to \"var_new\"\n",
    "            # Matrix Multiplying all elements, after A's diagonal (in a row) with all corresponding vars (in Vector, X), that do not have updated values yet\n",
    "            u = np.dot(A[j, j + 1:], var[j + 1:])\n",
    "            # Updating values of vars\n",
    "            var_new[j] = (B[j] - l - u) / A[j, j]\n",
    "        \n",
    "        # Checks, how close the updated values are, to the previous iteration's values and breaks the loop, if close enough (defined by \"tol\")\n",
    "        if np.allclose(var, var_new, atol=tol, rtol=0.):\n",
    "            print(\"\\nSolution converged, after {} iterations.\".format(i))\n",
    "            CONV_FLAG = True\n",
    "            break\n",
    "\n",
    "        var = var_new # Storing the new solution\n",
    "    # If solution is not obtained (no convergence), after ITER_LIM iterations | Note that, this \"else\" block belongs to the previous \"for\" statement and not any \"if\" statement\n",
    "    else:\n",
    "        CONV_FLAG = False\n",
    "\n",
    "    # If Solution converged\n",
    "    if CONV_FLAG:\n",
    "        print(\"\\nSOLUTION: \", var)\n",
    "        print(\"ERROR: \", np.dot(A, var) - B) # Error in the obtained solution\n",
    "    else:\n",
    "        print(\"\\nSolution did not converge, after the specified limit of {} iterations.\".format(ITER_LIM))\n",
    "\n",
    "\n",
    "# Testing the procedure\n",
    "A = np.array([[4., -1., 1.],\n",
    "              [4., -8., 1.],\n",
    "              [-2., 1., 5.]])\n",
    "\n",
    "B = np.array([7., 21., 15.])\n",
    "\n",
    "gauss_seidel(A, B, init_val=[0.,0.,0.], iter_lim=120, tol=1e-10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Back-Substitution Method\n",
    "\n",
    "#### Iterative Formula:\n",
    "\n",
    "For a $N$ by $N$ matrix, $A = D + U$, where $D$ is a diagonal matrix, containing all diagonal elements of $A$, while $U$ is a strictly upper triangular matrix, containing all other elements of $A$.\n",
    "\n",
    "$$\\mathbf {x} ^{(k+1)}=D^{-1}(\\mathbf {b} -U\\mathbf {x} ^{(k)})$$\n",
    "\n",
    "$$\\boxed{{\\displaystyle x_{i}^{(k+1)}={\\frac {1}{a_{ii}}}\\left(b_{i}-\\sum _{j=i+1}^{N-1}a_{ij}x_{j}^{(k)}\\right),\\quad i=0,1\\dots ,(N-1).}}$$\n",
    "Therefore,\n",
    "\n",
    "$$x_0^{(k+1)} = {\\frac {1}{a_{00}}}\\left(b_{0} - a_{01}x_{1}^{(k)} - a_{02}x_{2}^{(k)} - a_{03}x_{3}^{(k)}\\ldots\\right)$$\n",
    "\n",
    "$$x_1^{(k+1)} = {\\frac {1}{a_{11}}}\\left(b_{1} - a_{12}x_{2}^{(k)} - a_{13}x_{3}^{(k)}\\ldots\\right)$$\n",
    "\n",
    "$$x_2^{(k+1)} = {\\frac {1}{a_{22}}}\\left(b_{2} - a_{23}x_{3}^{(k)}\\ldots\\right)$$\n",
    "\n",
    "$$x_3^{(k+1)} = {\\frac {1}{a_{33}}}\\left(b_{3}\\right)$$\n",
    "And so on...\n",
    "\n",
    "#### Merits:\n",
    "\n",
    "* Much faster than Jacobi Iteration\n",
    "* Same space complexity as Jacobi Iteration\n",
    "\n",
    "#### Demerits:\n",
    "\n",
    "* Does not guarantee convergence\n",
    "* Works only for Upper Triangular Coefficient Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SOLVER: BACK_SUB\n",
      "\n",
      "System of Linear Equations:\n",
      "\n",
      "4.0x0 + -1.0x1 + 2.0x2 + 3.0x3 = 20.0\n",
      "0.0x0 + -2.0x1 + 7.0x2 + -4.0x3 = -7.0\n",
      "0.0x0 + 0.0x1 + 6.0x2 + 5.0x3 = 4.0\n",
      "0.0x0 + 0.0x1 + 0.0x2 + 1.0x3 = 1.0\n",
      "\n",
      "Iteration Limit:  120 \n",
      "\n",
      "Iteration: 1 | Current Solution: [0.0, 0.0, 0.0, 0.0]\n",
      "Iteration: 2 | Current Solution: [5.         3.5        0.66666667 1.        ]\n",
      "Iteration: 3 | Current Solution: [ 4.79166667  3.83333333 -0.16666667  1.        ]\n",
      "Iteration: 4 | Current Solution: [ 5.29166667  0.91666667 -0.16666667  1.        ]\n",
      "Iteration: 5 | Current Solution: [ 4.5625      0.91666667 -0.16666667  1.        ]\n",
      "\n",
      "Solution converged, after 4 iterations.\n",
      "\n",
      "SOLUTION:  [ 4.5625      0.91666667 -0.16666667  1.        ]\n",
      "ERROR:  [0. 0. 0. 0.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 4.5625    ,  0.91666667, -0.16666667,  1.        ])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def back_sub(A, B, init_val, iter_lim=100, tol=1e-8):\n",
    "    \"\"\"\n",
    "    # A: N by N np.array() | Contains coefficients of the variables (Matrix, A)\n",
    "    # B: N by 1 np.array() | Contains the constants on RHS (Vector, B)\n",
    "    # init_val: np.array() | Contains Initial Values\n",
    "    # iter_lim: Stores Iteration Limit | Default = 100\n",
    "    # tol: Tolerance value - how precise does the solution need to be | Default = 1e-8\n",
    "    \"\"\"\n",
    "    CONV_FLAG = False # Convergence Flag\n",
    "    ITER_LIM = iter_lim\n",
    "    var = init_val # Vector, X\n",
    "    \n",
    "    print(\"\\nSOLVER: BACK_SUB\\n\\nSystem of Linear Equations:\\n\")\n",
    "    for i in range(A.shape[0]):\n",
    "        row = [\"{}x{}\".format(A[i, j], j) for j in range(A.shape[1])]\n",
    "        print(\" + \".join(row), \"=\", B[i])\n",
    "\n",
    "    print(\"\\nIteration Limit: \", ITER_LIM, \"\\n\")\n",
    "    \n",
    "    for i in range(ITER_LIM):\n",
    "        print(\"Iteration: {} | Current Solution: {}\".format(i+1, var))\n",
    "        var_new = np.zeros_like(var) # stores updated values of all variables (Vector, X)\n",
    "\n",
    "        for j in range(A.shape[0]):\n",
    "            # Matrix Multiplying all elements, after A's diagonal (in a row) with all corresponding vars (in Vector, X)\n",
    "            u = np.dot(A[j, j + 1:], var[j + 1:])\n",
    "            # Updating values of vars\n",
    "            var_new[j] = (B[j] - u) / A[j, j]\n",
    "        \n",
    "        # Checks, how close the updated values are, to the previous iteration's values and breaks the loop, if close enough (defined by \"tol\")\n",
    "        if np.allclose(var, var_new, atol=tol, rtol=0.):\n",
    "            print(\"\\nSolution converged, after {} iterations.\".format(i))\n",
    "            CONV_FLAG = True\n",
    "            break\n",
    "\n",
    "        var = var_new # Storing the new solution\n",
    "    # If solution is not obtained (no convergence), after ITER_LIM iterations | Note that, this \"else\" block belongs to the previous \"for\" statement and not any \"if\" statement\n",
    "    else:\n",
    "        CONV_FLAG = False\n",
    "\n",
    "    # If Solution converged\n",
    "    if CONV_FLAG:\n",
    "        print(\"\\nSOLUTION: \", var)\n",
    "        print(\"ERROR: \", np.dot(A, var) - B) # Error in the obtained solution\n",
    "    else:\n",
    "        print(\"\\nSolution did not converge, after the specified limit of {} iterations.\".format(ITER_LIM))\n",
    "    \n",
    "    return var\n",
    "\n",
    "# Testing the procedure\n",
    "A = np.array([[4., -1., 2., 3.],\n",
    "              [0., -2., 7., -4.],\n",
    "              [0., 0., 6., 5.],\n",
    "              [0., 0., 0., 1.]])\n",
    "\n",
    "B = np.array([20., -7., 4., 1.])\n",
    "\n",
    "back_sub(A, B, init_val=[0.,0.,0.,0.], iter_lim=120, tol=1e-10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Forward-Substitution Method\n",
    "\n",
    "#### Iterative Formula:\n",
    "\n",
    "For a $N$ by $N$ matrix, $A = D + L$, where $D$ is a diagonal matrix, containing all diagonal elements of $A$, while $L$ is a strictly lower triangular matrix, containing all other elements of $A$.\n",
    "\n",
    "$$\\mathbf {x} ^{(k+1)}=D^{-1}(\\mathbf {b} -L\\mathbf {x} ^{(k)})$$\n",
    "\n",
    "$$\\boxed{{\\displaystyle x_{i}^{(k+1)}={\\frac {1}{a_{ii}}}\\left(b_{i}-\\sum _{j=0}^{i-1}a_{ij}x_{j}^{(k)}\\right),\\quad i=0,1\\dots ,(N-1).}}$$\n",
    "Therefore,\n",
    "\n",
    "$$x_0^{(k+1)} = {\\frac {1}{a_{00}}}\\left(b_{0}\\right)$$\n",
    "\n",
    "$$x_1^{(k+1)} = {\\frac {1}{a_{11}}}\\left(b_{1} - a_{10}x_{0}^{(k+1)}\\right)$$\n",
    "\n",
    "$$x_2^{(k+1)} = {\\frac {1}{a_{22}}}\\left(b_{2} - a_{20}x_{0}^{(k+1)} - a_{21}x_{1}^{(k+1)}\\right)$$\n",
    "\n",
    "$$x_3^{(k+1)} = {\\frac {1}{a_{33}}}\\left(b_{3} - a_{30}x_{0}^{(k+1)} - a_{31}x_{1}^{(k+1)} - a_{32}x_{2}^{(k+1)}\\right)$$\n",
    "And so on...\n",
    "\n",
    "#### Merits:\n",
    "\n",
    "* Much faster than Jacobi Iteration\n",
    "* Same space complexity as Jacobi Iteration\n",
    "\n",
    "#### Demerits:\n",
    "\n",
    "* Does not guarantee convergence\n",
    "* Works only for Lower Triangular Coefficient Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SOLVER: FORWARD_SUB\n",
      "\n",
      "System of Linear Equations:\n",
      "\n",
      "1.0x0 + 0.0x1 + 0.0x2 + 0.0x3 = 1.0\n",
      "5.0x0 + 6.0x1 + 0.0x2 + 0.0x3 = 4.0\n",
      "-4.0x0 + 7.0x1 + -2.0x2 + 0.0x3 = -7.0\n",
      "3.0x0 + 2.0x1 + -1.0x2 + 4.0x3 = 20.0\n",
      "\n",
      "Iteration Limit:  120 \n",
      "\n",
      "Iteration: 1 | Current Solution: [0.0, 0.0, 0.0, 0.0]\n",
      "Iteration: 2 | Current Solution: [1.         0.66666667 3.5        5.        ]\n",
      "Iteration: 3 | Current Solution: [ 1.         -0.16666667  3.83333333  4.79166667]\n",
      "Iteration: 4 | Current Solution: [ 1.         -0.16666667  0.91666667  5.29166667]\n",
      "Iteration: 5 | Current Solution: [ 1.         -0.16666667  0.91666667  4.5625    ]\n",
      "\n",
      "Solution converged, after 4 iterations.\n",
      "\n",
      "SOLUTION:  [ 1.         -0.16666667  0.91666667  4.5625    ]\n",
      "ERROR:  [0. 0. 0. 0.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 1.        , -0.16666667,  0.91666667,  4.5625    ])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def forward_sub(A, B, init_val, iter_lim=100, tol=1e-8):\n",
    "    \"\"\"\n",
    "    # A: N by N np.array() | Contains coefficients of the variables (Matrix, A)\n",
    "    # B: N by 1 np.array() | Contains the constants on RHS (Vector, B)\n",
    "    # init_val: np.array() | Contains Initial Values\n",
    "    # iter_lim: Stores Iteration Limit | Default = 100\n",
    "    # tol: Tolerance value - how precise does the solution need to be | Default = 1e-8\n",
    "    \"\"\"\n",
    "    CONV_FLAG = False # Convergence Flag\n",
    "    ITER_LIM = iter_lim\n",
    "    var = init_val # Vector, X\n",
    "    \n",
    "    print(\"\\nSOLVER: FORWARD_SUB\\n\\nSystem of Linear Equations:\\n\")\n",
    "    for i in range(A.shape[0]):\n",
    "        row = [\"{}x{}\".format(A[i, j], j) for j in range(A.shape[1])]\n",
    "        print(\" + \".join(row), \"=\", B[i])\n",
    "\n",
    "    print(\"\\nIteration Limit: \", ITER_LIM, \"\\n\")\n",
    "    \n",
    "    for i in range(ITER_LIM):\n",
    "        print(\"Iteration: {} | Current Solution: {}\".format(i+1, var))\n",
    "        var_new = np.zeros_like(var) # stores updated values of all variables (Vector, X)\n",
    "\n",
    "        for j in range(A.shape[0]):\n",
    "            # Matrix Multiplying all elements, after A's diagonal (in a row) with all corresponding vars (in Vector, X)\n",
    "            l = np.dot(A[j, :j], var[:j])\n",
    "            # Updating values of vars\n",
    "            var_new[j] = (B[j] - l) / A[j, j]\n",
    "        \n",
    "        # Checks, how close the updated values are, to the previous iteration's values and breaks the loop, if close enough (defined by \"tol\")\n",
    "        if np.allclose(var, var_new, atol=tol, rtol=0.):\n",
    "            print(\"\\nSolution converged, after {} iterations.\".format(i))\n",
    "            CONV_FLAG = True\n",
    "            break\n",
    "\n",
    "        var = var_new # Storing the new solution\n",
    "    # If solution is not obtained (no convergence), after ITER_LIM iterations | Note that, this \"else\" block belongs to the previous \"for\" statement and not any \"if\" statement\n",
    "    else:\n",
    "        CONV_FLAG = False\n",
    "\n",
    "    # If Solution converged\n",
    "    if CONV_FLAG:\n",
    "        print(\"\\nSOLUTION: \", var)\n",
    "        print(\"ERROR: \", np.dot(A, var) - B) # Error in the obtained solution\n",
    "    else:\n",
    "        print(\"\\nSolution did not converge, after the specified limit of {} iterations.\".format(ITER_LIM))\n",
    "        \n",
    "    return var\n",
    "\n",
    "\n",
    "# Testing the procedure\n",
    "A = np.array([[1., 0., 0., 0.],\n",
    "              [5., 6., 0., 0.],\n",
    "              [-4., 7., -2., 0.],\n",
    "              [3., 2., -1., 4.]])\n",
    "\n",
    "B = np.array([1., 4., -7., 20.])\n",
    "\n",
    "forward_sub(A, B, init_val=[0.,0.,0.,0.], iter_lim=120, tol=1e-10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Gauss-Jordan Elimination\n",
    "\n",
    "There are three types of elementary row operations which may be performed on the rows of a matrix:\n",
    "\n",
    "* Swap the positions of two rows.\n",
    "* Multiply a row by a non-zero scalar.\n",
    "* Add to one row a scalar multiple of another.\n",
    "\n",
    "Using these operations, we can convert the matrix, A, into \"row-reduced echelon form\", that can directly give us the solution for the system of linear equations.\n",
    "\n",
    "#### References: https://en.m.wikipedia.org/wiki/Gaussian_elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solution =  [ 0.36363636 -2.          3.54545455]\n"
     ]
    }
   ],
   "source": [
    "def gauss_elim(A, B):\n",
    "    \"\"\"\n",
    "    # A: N by N np.array() | Contains coefficients of the variables (Matrix, A)\n",
    "    # B: N by 1 np.array() | Contains the constants on RHS (Vector, B)\n",
    "    \"\"\"\n",
    "    # Prepping the Augmented Matrix\n",
    "    aug_mat = np.concatenate((A, np.reshape(B, (-1, 1))), axis=1)\n",
    "    # Convergence Flag\n",
    "    CONV_FLAG = True\n",
    "    # Position of leading nonzero, nondiagonal-element in a row\n",
    "    lead = 0\n",
    "    \n",
    "    # aug_mat.shape[0] == No. of rows\n",
    "    # aug_mat[0].shape or aug_mat.shape[1] == Number of Columns\n",
    "    rowCount = aug_mat.shape[0]\n",
    "    columnCount = aug_mat.shape[1]\n",
    "    \n",
    "    for r in range(rowCount):\n",
    "        if lead >= columnCount:\n",
    "            CONV_FLAG = False\n",
    "            break\n",
    "        i = r\n",
    "        \n",
    "        # Finding the leading nonzero element in a column\n",
    "        while aug_mat[i][lead] == 0:\n",
    "            i += 1\n",
    "            if i == rowCount:\n",
    "                i = r\n",
    "                lead += 1\n",
    "                if columnCount == lead:\n",
    "                    CONV_FLAG = False\n",
    "                    break\n",
    "        \n",
    "        aug_mat[i], aug_mat[r] = aug_mat[r], aug_mat[i] # Swapping rows\n",
    "        lv = aug_mat[r][lead]\n",
    "        aug_mat[r] = [mrx / float(lv) for mrx in aug_mat[r]]\n",
    "        for i in range(rowCount):\n",
    "            if i != r:\n",
    "                lv = aug_mat[i][lead]         \n",
    "                aug_mat[i] = [iv - lv*rv for rv,iv in zip(aug_mat[r], aug_mat[i])]\n",
    "        lead += 1\n",
    "        \n",
    "    if CONV_FLAG:\n",
    "        print(\"Solution = \", aug_mat[:, 3])\n",
    "    else:\n",
    "        print(\"Solution did not converge.\")\n",
    "\n",
    "\n",
    "# Testing the Procedure\n",
    "A = np.array([[4., -1., 1.],\n",
    "              [4., -8., 1.],\n",
    "              [-2., 1., 5.]])\n",
    "\n",
    "B = np.array([7., 21., 15.])\n",
    "\n",
    "gauss_elim(A, B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. LU Decomposition\n",
    "\n",
    "### Using the algorithm mentioned here: https://math.stackexchange.com/questions/404419/lu-decomposition-steps\n",
    "\n",
    "* Extension of Gaussian Elimintation\n",
    "* DOES NOT MAKE USE OF EXPLICIT PIVOTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Swap Matrix, S, in non-empty.\n",
      "LU is no longer == A.\n",
      "Use S, along with rowOp() to modify L, in order to get LU == A (in which case, L will no longer be Lower Triangular).\n",
      "You should also modify Vector B, similarly, if solving AX = B!\n",
      "\n",
      "A = \n",
      " [[ 0.  4.  2.  3.]\n",
      " [ 0.  1.  4.  4.]\n",
      " [-1.  0.  1.  0.]\n",
      " [ 2.  0.  4.  1.]]\n",
      "L = \n",
      " [[ 1.          0.          0.          0.        ]\n",
      " [-0.          1.          0.          0.        ]\n",
      " [-0.          4.          1.          0.        ]\n",
      " [-2.          0.         -0.42857143  1.        ]]\n",
      "L_FactorOfAButNotLowerTriangular = \n",
      " [[-0.          4.          1.          0.        ]\n",
      " [-0.          1.          0.          0.        ]\n",
      " [ 1.          0.          0.          0.        ]\n",
      " [-2.          0.         -0.42857143  1.        ]]\n",
      "U = \n",
      " [[ -1.           0.           1.           0.        ]\n",
      " [  0.           1.           4.           4.        ]\n",
      " [  0.           0.         -14.         -13.        ]\n",
      " [  0.           0.           0.          -4.57142857]]\n",
      "LU (Should NOT be == A) =\n",
      " [[-1.  0.  1.  0.]\n",
      " [ 0.  1.  4.  4.]\n",
      " [ 0.  4.  2.  3.]\n",
      " [ 2.  0.  4.  1.]]\n",
      "L_FactorOfAButNotLowerTriangular*U (Should be == A) =\n",
      " [[ 0.  4.  2.  3.]\n",
      " [ 0.  1.  4.  4.]\n",
      " [-1.  0.  1.  0.]\n",
      " [ 2.  0.  4.  1.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def rowOp(A, S):\n",
    "    \"\"\"\n",
    "    Helper function to LU()\n",
    "    Performs Row Swaps, according to Index Tuples in S\n",
    "    INPUT:\n",
    "    A: Numpy Matrix\n",
    "    S: Numpy Matrix | Stores Row Swaps\n",
    "    OUTPUT:\n",
    "    A: Modified Matrix\n",
    "    \"\"\"\n",
    "    # Modifying L, such that the Swaps are reversed, so as to give back the original Matrix, A\n",
    "    # However, L is no longer Lower Triangular\n",
    "    for j, i in S:\n",
    "        A[[j, i]] = A[[i, j]]\n",
    "        \n",
    "    return A\n",
    "\n",
    "def LU(A):\n",
    "    \"\"\"\n",
    "    Returns LU Decomposition of A\n",
    "    DEPENDENCY: rowOp()\n",
    "    INPUT:\n",
    "    A: Numpy Matrix | Matrix, to be decomposed\n",
    "    OUTPUT:\n",
    "    L: Numpy Matrix | Lower Triangular Factor of A\n",
    "    U: Numpy Matrix | Upper Triangular Factor of A\n",
    "    S: Numpy Matrix | Stores Row Swaps\n",
    "    \"\"\"\n",
    "    n = A.shape[0]\n",
    "    U = A.copy()\n",
    "    L = np.identity(n)\n",
    "    S = [] # List of Index Tuples | Stores swaps\n",
    "    \n",
    "    for i in range(n):\n",
    "        lead = 0\n",
    "        j = i\n",
    "        while U[j][lead] == 0:\n",
    "            j += 1\n",
    "            if j == n:\n",
    "                j = i\n",
    "                lead += 1\n",
    "\n",
    "        if j != i:\n",
    "            U[[j, i]] = U[[i, j]] # Swapping rows\n",
    "            S.append((j, i)) # Storing Swap\n",
    "\n",
    "        for k in range(i+1, n):\n",
    "            L[k, lead] = U[k, lead]/U[i, lead] # Storing coefficients in L\n",
    "            U[k] = [kv - L[k, lead]*iv for kv, iv in zip(U[k], U[i])] # Modifying U\n",
    "\n",
    "    if S: # S is non-empty\n",
    "        print(\"WARNING: Swap Matrix, S, in non-empty.\\nLU is no longer == A.\\nUse S, along with rowOp() to modify L, in order to get LU == A (in which case, L will no longer be Lower Triangular).\\nYou should also modify Vector B, similarly, if solving AX = B!\\n\")\n",
    "    \n",
    "    return L, U, S\n",
    "    \n",
    "\n",
    "\n",
    "# MODULE TEST\n",
    "A = np.array([[0, 4, 2, 3],\n",
    "              [0, 1, 4, 4],\n",
    "              [-1, 0, 1, 0],\n",
    "              [2, 0, 4, 1]], dtype=float)\n",
    "\n",
    "l, u, s = LU(A)\n",
    "L_FactorOfAButNotLowerTriangular, Lu = l.copy(), []\n",
    "\n",
    "\n",
    "if s:\n",
    "    L_FactorOfAButNotLowerTriangular = rowOp(L_FactorOfAButNotLowerTriangular, s) # RIP PEP Naming Schemes\n",
    "    Lu = L_FactorOfAButNotLowerTriangular @ u # Should be == A\n",
    "\n",
    "lu = l @ u # Matrix-multiplying l and u | Should NOT be == A, if S is non-empty\n",
    "\n",
    "print(\"A = \\n\", A)\n",
    "print(\"L = \\n\", l)\n",
    "print(\"L_FactorOfAButNotLowerTriangular = \\n\", L_FactorOfAButNotLowerTriangular)\n",
    "print(\"U = \\n\", u)\n",
    "print(\"LU (Should NOT be == A) =\\n\", lu)\n",
    "print(\"L_FactorOfAButNotLowerTriangular*U (Should be == A) =\\n\", Lu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LU Decomposition -  BONUS STUFF\n",
    "\n",
    "* Linear Equation Solver (Using LU Decomposition)\n",
    "* Determinant Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SOLVER: FORWARD_SUB\n",
      "\n",
      "System of Linear Equations:\n",
      "\n",
      "1.0x0 + 0.0x1 + 0.0x2 + 0.0x3 = 1.0\n",
      "5.0x0 + 1.0x1 + 0.0x2 + 0.0x3 = 4.0\n",
      "-4.0x0 + 1.1666666666666667x1 + 1.0x2 + 0.0x3 = -7.0\n",
      "3.0x0 + 0.3333333333333333x1 + 0.5x2 + 1.0x3 = 20.0\n",
      "\n",
      "Iteration Limit:  100 \n",
      "\n",
      "Iteration: 1 | Current Solution: [1.0, 1.0, 1.0, 1.0]\n",
      "Iteration: 2 | Current Solution: [ 1.         -1.         -4.16666667 16.16666667]\n",
      "Iteration: 3 | Current Solution: [ 1.         -1.         -1.83333333 19.41666667]\n",
      "Iteration: 4 | Current Solution: [ 1.         -1.         -1.83333333 18.25      ]\n",
      "\n",
      "Solution converged, after 3 iterations.\n",
      "\n",
      "SOLUTION:  [ 1.         -1.         -1.83333333 18.25      ]\n",
      "ERROR:  [0. 0. 0. 0.]\n",
      "\n",
      "SOLVER: BACK_SUB\n",
      "\n",
      "System of Linear Equations:\n",
      "\n",
      "1.0x0 + 0.0x1 + 0.0x2 + 0.0x3 = 1.0\n",
      "0.0x0 + 6.0x1 + 0.0x2 + 0.0x3 = -1.0\n",
      "0.0x0 + 0.0x1 + -2.0x2 + 0.0x3 = -1.833333333333333\n",
      "0.0x0 + 0.0x1 + 0.0x2 + 4.0x3 = 18.25\n",
      "\n",
      "Iteration Limit:  100 \n",
      "\n",
      "Iteration: 1 | Current Solution: [1.0, 1.0, 1.0, 1.0]\n",
      "Iteration: 2 | Current Solution: [ 1.         -0.16666667  0.91666667  4.5625    ]\n",
      "\n",
      "Solution converged, after 1 iterations.\n",
      "\n",
      "SOLUTION:  [ 1.         -0.16666667  0.91666667  4.5625    ]\n",
      "ERROR:  [0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# Linear Equation Solver\n",
    "# Ax = b => LUx = rowOp(b) => First solve for Ly = rowOp(b), then Solve for Ux = y\n",
    "# DEPENDENCY: rowOp()\n",
    "A = np.array([[1., 0., 0., 0.],\n",
    "              [5., 6., 0., 0.],\n",
    "              [-4., 7., -2., 0.],\n",
    "              [3., 2., -1., 4.]])\n",
    "\n",
    "b = np.array([1., 4., -7., 20.])\n",
    "\n",
    "L, U, S = LU(A)\n",
    "L_FacNotlower = L.copy()\n",
    "\n",
    "# Printing out the Solution is handled by back_sub() and forward_sub()\n",
    "if S: # S is not empty\n",
    "    L_FacNotlower = rowOp(L_FacNotlower, s) # RIP PEP Naming Schemes\n",
    "    b = rowOp(b, S)\n",
    "    y = forward_sub(L_FacNotlower, b, init_val=[1., 1., 1., 1.])\n",
    "    x = back_sub(U, y, init_val=[1., 1., 1., 1.])\n",
    "    \n",
    "else:\n",
    "    del L_FacNotlower # If S is empty, L_FacNotlower == L and so, L_FacNotLower is not needed\n",
    "    y = forward_sub(L, b, init_val=[1., 1., 1., 1.])\n",
    "    x = back_sub(U, y, init_val=[1., 1., 1., 1.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Determinant of A = -48.0\n",
      "Determinant of A, using numpy.linalg.det = -48.00000000000003\n"
     ]
    }
   ],
   "source": [
    "# Determinant Calculation\n",
    "# Det(A) = Det(LU)*(-1)**(len(S))\n",
    "# https://en.wikipedia.org/wiki/LU_decomposition#Computing_the_determinant\n",
    "def DetLU(A):\n",
    "    \"\"\"\n",
    "    Returns the determinant of A\n",
    "    INPUT:\n",
    "    A: Numpy Matrix | Matrix, whose determinant is to be calculated\n",
    "    OUTPUT:\n",
    "    det: Float | Determinant of A\n",
    "    \"\"\"\n",
    "    L, U, S = LU(A) # Getting LU Decomposition of A\n",
    "    n = A.shape[0]\n",
    "    nS = len(S)\n",
    "    det = 1\n",
    "    for i in range(n):\n",
    "        det *= L[i, i]*U[i, i]\n",
    "    \n",
    "    det *= (-1)**nS\n",
    "    return det\n",
    "       \n",
    "print(\"Determinant of A = {}\".format(DetLU(A)))\n",
    "print(\"Determinant of A, using numpy.linalg.det = {}\".format(np.linalg.det(A)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Inverse of a Matrix:\n",
    "\n",
    "### Reference: https://integratedmlai.com/matrixinverse/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inverse of A = \n",
      " [[ 0.26623377 -0.03896104 -0.04545455]\n",
      " [ 0.14285714 -0.14285714  0.        ]\n",
      " [ 0.07792208  0.01298701  0.18181818]]\n",
      "A * Inv(A) = \n",
      " [[ 1.00000000e+00  1.38777878e-17 -4.16333634e-17]\n",
      " [ 0.00000000e+00  1.00000000e+00  0.00000000e+00]\n",
      " [ 5.55111512e-17  0.00000000e+00  1.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "def Inv(A):\n",
    "    \"\"\"\n",
    "    Returns Inverse of A\n",
    "    DEPENDENCY: DetLU()\n",
    "    INPUT:\n",
    "    A: Numpy Matrix | Matrix, to be inverted\n",
    "    OUTPUT:\n",
    "    inv: Numpy Matrix | Inverse of A\n",
    "    \"\"\"\n",
    "    # Prepping the Augmented Matrix\n",
    "    n = A.shape[0]\n",
    "    aug_mat = A.copy()\n",
    "    \n",
    "    inv = np.identity(n)\n",
    "    \n",
    "    # Input Checks\n",
    "    if DetLU(A) == 0:\n",
    "        print(\"WARNING: Determinant of this matrix = 0.\\nERROR: Matrix cannot be inverted!\")\n",
    "        return None\n",
    "    elif A.shape[0] != A.shape[1]:\n",
    "        print(\"WARNING: Matrix is not a Square Matrix.\\nERROR: Matrix cannot be inverted!\")\n",
    "        return None\n",
    "\n",
    "    # Position of leading nonzero, nondiagonal-element in a row\n",
    "    lead = 0\n",
    "    \n",
    "    for r in range(n):\n",
    "        i = r\n",
    "        \n",
    "        # Finding the leading nonzero element in a column\n",
    "        while aug_mat[i][lead] == 0:\n",
    "            i += 1\n",
    "            if i == n:\n",
    "                i = r\n",
    "                lead += 1\n",
    "        \n",
    "        aug_mat[[i, r]] = aug_mat[[r, i]] # Swapping rows\n",
    "        inv[[i, r]] = inv[[r, i]] # Same operations to be performed on inv\n",
    "        \n",
    "        lv = aug_mat[r][lead]\n",
    "        aug_mat[r] = [mrx / float(lv) for mrx in aug_mat[r]]\n",
    "        inv[r] = [mrx / float(lv) for mrx in inv[r]]\n",
    "        for i in range(n):\n",
    "            if i != r:\n",
    "                lv = aug_mat[i][lead]         \n",
    "                aug_mat[i] = [iv - lv*rv for rv,iv in zip(aug_mat[r], aug_mat[i])]\n",
    "                inv[i] = [iv - lv*rv for rv,iv in zip(inv[r], inv[i])]\n",
    "        lead += 1\n",
    "        \n",
    "    return inv\n",
    "\n",
    "\n",
    "# Testing the Procedure\n",
    "A = np.array([[4., -1., 1.],\n",
    "              [4., -8., 1.],\n",
    "              [-2., 1., 5.]])\n",
    "\n",
    "print(\"Inverse of A = \\n\", Inv(A))\n",
    "\n",
    "print(\"A * Inv(A) = \\n\", Inv(A) @ A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Cholesky Decomposition\n",
    "(From https://en.wikipedia.org/wiki/Cholesky_decomposition)\n",
    "\n",
    "If we write out the equation:\n",
    "$${\\begin{aligned}\\mathbf {A} =\\mathbf {LL} ^{T}&={\\begin{pmatrix}L_{11}&0&0\\\\L_{21}&L_{22}&0\\\\L_{31}&L_{32}&L_{33}\\\\\\end{pmatrix}}{\\begin{pmatrix}L_{11}&L_{21}&L_{31}\\\\0&L_{22}&L_{32}\\\\0&0&L_{33}\\end{pmatrix}}\\\\&={\\begin{pmatrix}L_{11}^{2}&&({\\text{symmetric}})\\\\L_{21}L_{11}&L_{21}^{2}+L_{22}^{2}&\\\\L_{31}L_{11}&L_{31}L_{21}+L_{32}L_{22}&L_{31}^{2}+L_{32}^{2}+L_{33}^{2}\\end{pmatrix}},\\end{aligned}}$$\n",
    "\n",
    "we obtain the following:\n",
    "\n",
    "\\begin{aligned}\\mathbf {L} ={\\begin{pmatrix}{\\sqrt {A_{11}}}&0&0\\\\A_{21}/L_{11}&{\\sqrt {A_{22}-L_{21}^{2}}}&0\\\\A_{31}/L_{11}&\\left(A_{32}-L_{31}L_{21}\\right)/L_{22}&{\\sqrt {A_{33}-L_{31}^{2}-L_{32}^{2}}}\\end{pmatrix}}\\end{aligned}\n",
    "\n",
    "and therefore the following formulas for the entries of L:\n",
    "\n",
    "$$L_{j,j}={\\sqrt {A_{j,j}-\\sum _{k=1}^{j-1}L_{j,k}^{2}}}$$\n",
    "\n",
    "$$L_{i,j}={\\frac {1}{L_{j,j}}}\\left(A_{i,j}-\\sum _{k=1}^{j-1}L_{i,k}L_{j,k}\\right)\\quad {\\text{for }}i>j$$\n",
    "\n",
    "Cholesky Decomposition is usually twice as efficient as LU Decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cholesky Factor:\n",
      " [[1.         0.        ]\n",
      " [0.         2.23606798]]\n"
     ]
    }
   ],
   "source": [
    "def choles_decomp(A):\n",
    "    \"\"\"\n",
    "    Returns the Cholesky Factor of A\n",
    "    DOES NOT CHECK FOR A's ELIGIBILITY TO BE CHOLESKY-DECOMPOSED\n",
    "    INPUT:\n",
    "    A: Numpy Matrix | Matix, to be decomposed\n",
    "    OUTPUT:\n",
    "    L: Numpy Matrix | Cholesky Factor of A\n",
    "    \"\"\"\n",
    "    # L is the Cholesky Factor of A\n",
    "    L = np.zeros_like(A)\n",
    "    for i, (Ai, Li) in enumerate(zip(A, L)):\n",
    "        for j, Lj in enumerate(L[:i+1]):\n",
    "            s = sum(Li[k] * Lj[k] for k in range(j))\n",
    "            Li[j] = np.sqrt(Ai[i] - s) if (i == j) else (1.0 / Lj[j] * (Ai[j] - s)) # Using the formulae from the description above\n",
    "\n",
    "    print(\"Cholesky Factor:\\n\", L)\n",
    "\n",
    "A = np.array([[1., 0.],\n",
    "              [0., 5.]])\n",
    "\n",
    "choles_decomp(A)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
